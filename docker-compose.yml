services:
  ollama:
    image: ollama/ollama
    container_name: ollama
    gpus: all
    environment:
      - OLLAMA_ORIGINS=*
      - OLLAMA_CONTEXT_LENGTH=4096
      - OLLAMA_NUM_PARALLEL=2
      - OLLAMA_THREADS=4
      - OLLAMA_CPU_OFFLOAD=true
    volumes:
      - ./ollama-models:/root/.ollama/models
    ports:
      - "11434:11434"

  mariadb:
    image: mariadb:11
    restart: unless-stopped
    environment:
      - MARIADB_ROOT_PASSWORD=secret
      - MARIADB_DATABASE=chatdb
    volumes:
      - ./db:/var/lib/mysql
    ports:
      - "3306:3306"

  api:
    build: ./api
    container_name: chat-api
    depends_on:
      - mariadb
    environment:
      - DB_HOST=mariadb
      - DB_USER=root
      - DB_PASS=secret
      - DB_NAME=chatdb
      - OLLAMA_URL=http://ollama:11434
    ports:
      - "4000:4000"

  web:
    image: nginx:alpine
    container_name: deepseek-web
    volumes:
      - ./web:/usr/share/nginx/html:ro
    ports:
      - "3001:80"
