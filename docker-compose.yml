services:
  ollama:
    image: ollama/ollama
    container_name: ollama
    gpus: all
    environment:
      - OLLAMA_ORIGINS=*
      - OLLAMA_CONTEXT_LENGTH=4096
      - OLLAMA_NUM_PARALLEL=2
      - OLLAMA_THREADS=4
      - OLLAMA_CPU_OFFLOAD=true
    volumes:
      - ./ollama-models:/root/.ollama/models
    ports:
      - "11434:11434"
    # Vous avez déjà tiré qwen2:7b-instruct-q4_K_M dans ./ollama-models

  web:
    image: nginx:alpine
    container_name: deepseek-web
    volumes:
      - ./web:/usr/share/nginx/html:ro
    ports:
      - "3001:80"
    environment:
      - OLLAMA_ORIGINS=*
